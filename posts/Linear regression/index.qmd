---
title: "K-Nearest Neighbors (KNN) with Iris Dataset in R"
author: "Kamal Chhetri"
date: "2023-10-18"
categories:
  - News
  - Code
  - Analysis
---

## Introduction

K-Nearest Neighbors (KNN) is a simple yet powerful classification algorithm. It classifies a data point based on how its neighbors are classified. In this blog post, we will use the Iris dataset to understand how KNN works using R.

## What is KNN?

KNN is a type of instance-based learning, or lazy learning, where the function is only approximated locally and all computation is deferred until function evaluation. It's both a classification and regression method.

## The Iris Dataset

The Iris dataset is a multivariate dataset introduced by the British statistician and biologist Ronald Fisher in his 1936 paper. The dataset consists of 50 samples from each of three species of Iris flowers (Iris setosa, Iris virginica, and Iris versicolor). Four features were measured from each sample: the lengths and the widths of the sepals and petals.

Load necessary libraries

```{r}
library(class)
library(ggplot2)
```

Set the random seed for reproducibility

```{r}
set.seed(0)
```

Split data into training and test sets

```{r}
nsample = nrow(iris)
train.ix = sample(1:nsample, round(nsample / 2))
test.ix = setdiff(1:nsample, train.ix)
train.X = iris[train.ix, 3:4]  # Only use Petal.Length, Petal.Width
train.Y = iris[train.ix, 5]    # Factor data type
test.X = iris[test.ix, 3:4]
test.Y = iris[test.ix, 5]
```

Perform classification for the test set

```{r}
k_value = 3
pred.Y = knn(train.X, test.X, train.Y, k = k_value)
mcr = mean(test.Y != pred.Y)
```

Create a data frame to store test data and predicted labels

```{r}
results_df <- data.frame(
  Petal.Length = test.X[, 1],
  Petal.Width = test.X[, 2],
  Actual_Class = test.Y,
  Predicted_Class = pred.Y
)
```

Plot the test data points color-coded by their predicted class

```{r}
ggplot(results_df, aes(x = Petal.Length, y = Petal.Width, color = factor(Actual_Class), shape = factor(Predicted_Class))) +
  geom_point(size = 3) +
  labs(x = "Petal Length", y = "Petal Width", title = paste("KNN Classification (k =", k_value, ")")) +
  scale_color_discrete(name = "Actual Class") +
  scale_shape_discrete(name = "Predicted Class") +
  theme_minimal()
```

Print the confusion matrix

```{r}
confusion_matrix <- table(test.Y, pred.Y)
print("Confusion Matrix:")
print(confusion_matrix)
```

Calculate the misclassification rate

```{r}
print(paste("Misclassification Rate:", mcr))
```

```{r}
print(paste("Misclassification Rate:", mcr))
```

```{r}

```
